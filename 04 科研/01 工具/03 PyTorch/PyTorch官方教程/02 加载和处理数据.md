

# 综述

- 处理机器学习问题时，有大量的时间都是花在处理数据上，而 PyTorch 提供了很多工具类，使得加载和处理数据十分容易
- 为了增强代码的可读性，本教程将讲述对于一个原始的数据集，如何加载、预处理和增强数据
- 为了运行先关代码，需要按下下述包，并导入对应的包
    - scikit-image : 用于图片的转换
    - pandas : 快速读取 csv 文件

```py
from __future__ import print_function, division
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

plt.ion()   # interactive mode
```
- 我们将要处理这样的 [faces数据集](https://download.pytorch.org/tutorial/faces.zip)，该数据集包含一堆的图片和一个 csv 文件， csv 文件中的每一行描述了一个样本，第一列为该图片的名称，之后的 68×2 个列描述了在图上的 68 个点，分别按 x0,y0,x1,y1,x2,y2 这样序列排序
- 使用 pandas 快速读取 csv 文件，并读取一个样本查看信息
```py
# panda 打开 csv
landmarks_frame = pd.read_csv('faces/face_landmarks.csv')

n = 65 # 第66个数据，文件中的第67行
img_name = landmarks_frame.iloc[n, 0] # 文件名 
landmarks = landmarks_frame.iloc[n, 1:].as_matrix() # 每行的68个点
landmarks = landmarks.astype('float').reshape(-1, 2) # reshape

print('Image name: {}'.format(img_name))
print('Landmarks shape: {}'.format(landmarks.shape))  # 打印出点的shape -> (68, 2)
print('First 4 Landmarks: {}'.format(landmarks[:4]))  # 打印出前4个点的坐标
```
- 可视化单个样本：
```py
def show_landmarks(image, landmarks):
    """
    绘制图片和图片上的68个点
    :param image: 存储图片的 ndarray
    :param landmarks: 68个点的坐标
    :return: 
    """
    # 绘制图像
    plt.imshow(image)
    # 绘制68个散点,s指定点大小，marker指定点类型为点，c指定颜色为红色
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')
    plt.pause(0.001)  # pause a bit so that plots are updated

plt.figure()
# skimage的io，读取图片并返回 ndarray
img_ndarray = io.imread(os.path.join('faces/', img_name))
show_landmarks(img_ndarray, landmarks)
plt.show()
```

# Dataset 类

- torch.utils.data.Dataset 是一个抽象类，其表示一个数据集，用户自定义的数据集类需要继承该类，并复写下述方法：
    - \_\_len\_\_: 返回数据集的 size
    - \_\_getitem\_\_ : 获取单个样本，为了能支持使用下标访问 dataset\[i\]
- 让我们自定义一个 Dataset 类来读取前面提供的数据集，我们将在 \_\_init\_\_ 方法内部读取 csv 文件，但在 \_\_getitem\_\_ 内部读取具体的某张图片，这样能节省内存，因为因为只有需要时才读取某图片
- 数据集的一个样本是一个字典形如：{'image': image, 'landmarks': landmarks}，
- 程序会使用可选参数 transform 指定需要在每个样本做的额外预处理工作，预处理的类需要自己定义，transform 将在下部分介绍
- 首先是自定义的类：
```py
# 自定义一个 DataSet，继承 DataSet 表示这是一个数据集
class FaceLandmarksDataset(Dataset):
    """Face Landmarks dataset."""

    def __init__(self, csv_file, root_dir, transform=None):
        """
        Args:
            csv_file (string): csv 文件路径
            root_dir (string): 对应的图片的根目录
            transform (callable, optional): 数据预处理器
        """
        # 读取 csv 文件
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.landmarks_frame)

    def __getitem__(self, idx):
        # 取得图片路径
        img_name = os.path.join(self.root_dir,
                                self.landmarks_frame.iloc[idx, 0])
        # 读取为 ndarray
        image = io.imread(img_name)
        # 序列转化为 ndarray
        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix()
        # ndarray 变换类型并调整形状
        landmarks = landmarks.astype('float').reshape(-1, 2)
        # 构造单个样本，字典格式
        sample = {'image': image, 'landmarks': landmarks}

        # 若预处理器不为空，对样本执行预处理
        if self.transform:
            sample = self.transform(sample)

        return sample
```
- 然后是创建该类实例读取 faces 数据集，并绘制部分样本
```py
# 创建自定义的 Dataset 读取数据
face_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',
                                    root_dir='faces/') # 调用自定义的数据集类读取数据

# 绘图
fig = plt.figure()

# 迭代所有数据，但其实只迭代4个
for i in range(len(face_dataset)):
    sample = face_dataset[i]  # 取出当前数据

    # 打印图片 shape 和点的 shape
    print(i, sample['image'].shape, sample['landmarks'].shape)

    # 在子图上绘制当前样本
    ax = plt.subplot(1, 4, i + 1)  # ax 表示当前子图
    # 自动调整子图参数，使其填满整个区域
    plt.tight_layout()
    ax.set_title('Sample #{}'.format(i))  # 子图标题
    ax.axis('off')  # 关闭子图的坐标轴
    show_landmarks(**sample)  # 调用前面定义的函数绘制样本

    # 4 个以后直接退出，即只遍历4个数据
    if i == 3:
        plt.show()
        break
```

# Transforms

- 显然，上述数据存在一个问题：大多样本不是同样的大小，而大多数的神经网络要求接受等大小的图片，因此我们还有编写数据预处理代码，让我们创建三个 transforms 类用于输入数据的转换：
    - Rescale : 缩放图片
    - RandomCrop : 随机裁剪，这是数据增强技术
    - ToTensor : 将 np 数组转换为 Tensor （主要体现在交换维度上）
- 一般直接读取到的图片，通道往往在 ndarray 的第 2 维，即 w * h * c，而在 Tensor 中，要求图片通道在第 0 维，即 c c * w * h，因此需要使用 ToTensor 进行转换
- 我们将转 transform 实现为可调用的类而不是简单的函数，这样就不必再每次执行转换时传递转换参数，我们只需要实现 \_\_call\_\_ 函数，若有需要还可以实现 \_\_init\_\_ 函数，之后我们便可以使用类似下面的代码执行转换：
```py
tsfm = Transform(params)
transformed_sample = tsfm(sample)
```
- 下面即自定义的三个用于 transform 的类
```py
# 数据预处理，涉及图像缩放、随机裁剪（数据增加技术）、从 numpy 图像转换为 torch 的 Tensor
# 我们可以定义用于上述处理的三个类，编写 __init__ 和 __call__ 方法

class Rescale(object):
    """
    将图片缩放到指定的size，size可能是一个int或是一个tuple
    Args:
        output_size (tuple or int): Desired output size. If tuple, output is
            matched to output_size. If int, smaller of image edges is matched
            to output_size keeping aspect ratio the same.
    """

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        self.output_size = output_size

    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']

        h, w = image.shape[:2]
        if isinstance(self.output_size, int):
            # 若size是int，则将小的那条边调整为size，另一条边等比例缩放
            if h > w:
                new_h, new_w = self.output_size * h / w, self.output_size
            else:
                new_h, new_w = self.output_size, self.output_size * w / h
        else:
            # 否则缩放到指定的tuple大小
            new_h, new_w = self.output_size

        # 计算结果可能是浮点数，截取为int
        new_h, new_w = int(new_h), int(new_w)
        # 调用skimage的transform缩放图片大小
        img = transform.resize(image, (new_h, new_w))

        # h and w are swapped for landmarks because for images,
        # x and y axes are axis 1 and 0 respectively
        # 图片缩放了，对应的点也要缩放
        landmarks = landmarks * [new_w / w, new_h / h]

        return {'image': img, 'landmarks': landmarks}

# 到 output_size
class RandomCrop(object):
    """
    随机裁剪图片到指定size
    Args:
        output_size (tuple or int): Desired output size. If int, square crop
            is made.
    """

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        if isinstance(output_size, int):
            self.output_size = (output_size, output_size)
        else:
            assert len(output_size) == 2
            self.output_size = output_size

    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']

        # 原来的宽高
        h, w = image.shape[:2]
        # 目标裁剪宽高
        new_h, new_w = self.output_size

        # 根据原有宽高和新宽高随机生成左上角的点
        top = np.random.randint(0, h - new_h)
        left = np.random.randint(0, w - new_w)

        # 裁剪图片：数组切片
        image = image[top: top + new_h,
                      left: left + new_w]

        # 对应的点也要偏移，可能会产生负数
        landmarks = landmarks - [left, top]

        return {'image': image, 'landmarks': landmarks}

class ToTensor(object):
    """
    将 ndarray 转换为 Tensor，并将通道换到第0维
    该 transform 一般作为最后一个 transform
    """

    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']

        # swap color axis because
        # numpy image: H x W x C
        # torch image: C X H X W
        # 维度变换：转置（这真的好抽象）
        image = image.transpose((2, 0, 1))
        return {'image': torch.from_numpy(image),
                'landmarks': torch.from_numpy(landmarks)}
```


## Compose Transforms

- torchvision.transforms.Compose ，可以将多个 transform 组合起来，以提供给 DataSet 的 transform 属性，这样就能在数据集上同时使用多个 transform
- 测试上面定义的 transform 的效果：
```py
# 调用自定义的转换器
scale = Rescale(256)
crop = RandomCrop(128)
# torchvision.transforms中提供了Compose，可以将多个transform组合起来，以提供给DataSet
composed = transforms.Compose([Rescale(256),
                               RandomCrop(224)])

# Apply each of the above transforms on sample.
fig = plt.figure()
sample = face_dataset[65]
for i, tsfrm in enumerate([scale, crop, composed]):
    transformed_sample = tsfrm(sample) # 分别利用不同的转换器作转换

    ax = plt.subplot(1, 3, i + 1) # 绘制子图
    plt.tight_layout() # 自动适应图片大小
    ax.set_title(type(tsfrm).__name__) # 字头名称
    show_landmarks(**transformed_sample)

plt.show()
```

# 迭代 Dataset

- 让我们综合前述内容，来创建数据集对象，提供 transform 并读取数据
- 创建 Dataset 时，同时指定 transform 参数，以对数据进行预处理
```py
# 创建数据集对象时，同时提供transform，为自定义的三个transform的组合，用于预处理输入样本
transformed_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',
                                           root_dir='faces/',
                                           transform=transforms.Compose([
                                               Rescale(256),
                                               RandomCrop(224),
                                               ToTensor()
                                           ])) # 定义数据集，并提供转换器，DataSet自动对每个sample执行转换器

# 然后遍历数据集，打印出样本规模
for i in range(len(transformed_dataset)):
    sample = transformed_dataset[i]

    print(i, sample['image'].size(), sample['landmarks'].size())

    if i == 3:
        break
```
- 但迭代单个样本，我们丢失了很多特性：
    - Batch Data
    - Shuffle Data
    - 并行读取 Data
- torch.utils.data.DataLoader 是一个迭代器，其提供了上述特性
- collate_fn 是 DataLoader 的构造函数可选参数，指向一个函数，即 Batch 策略，但大多数情况下默认情况已经够用了
- DataLoader 类常用参数为 DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=2) ，其中 num_workers 线程参数，在 Win 下可能会报错，此时可尝试将 num_workers 设置为 0，即不采用多线程加载，1 有时候也会报错
- 下面是 DataLoader 样例代码：
```py
def show_landmarks_batch(sample_batched):
    """
    绘制一个 Batch 的图片
    """
    images_batch, landmarks_batch = \
            sample_batched['image'], sample_batched['landmarks']
    batch_size = len(images_batch)
    im_size = images_batch.size(2)

    grid = utils.make_grid(images_batch)
    # 要绘制需要将通道换到第三维
    plt.imshow(grid.numpy().transpose((1, 2, 0)))

    for i in range(batch_size):
        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size,
                    landmarks_batch[i, :, 1].numpy(),
                    s=10, marker='.', c='r')

        plt.title('Batch from dataloader')

for i_batch, sample_batched in enumerate(dataloader):
    print(i_batch, sample_batched['image'].size(),
          sample_batched['landmarks'].size())

    # observe 4th batch and stop.
    if i_batch == 3:
        plt.figure()
        show_landmarks_batch(sample_batched)
        plt.axis('off')
        plt.ioff()
        plt.show()
        break
```

# 后记 : torchvision

- 我们已经学习了 datasets, transforms 和 dataloader，这也是 PyTorch 中和数据相关的三个核心组件
- torchvision 包提供了许多常见的数据集和 transforms，对于这些常见的数据集，你不必再自己编写自定义 Dataset 和 transforms ，torchvision 已经帮你写好，你直接使用即可
- torchvision 还提供了一个更加通用的用于读取图片的 Dataset：ImageFolder，它假设你按如下方式组织数据：在某个目录下，为类别文件夹，每个类别文件夹为该类的样本：
```
root/ants/xxx.png
root/ants/xxy.jpeg
root/ants/xxz.png
.
.
.
root/bees/123.jpg
root/bees/nsdf3.png
root/bees/asd932_.png
```
- 在上述描述中，‘ants’, ‘bees’ etc. 是类标签
- 类似的，torchvision 也提供了一些对于图片数据常用的 transform，我们可以组合并使用它们
```py
import torch
from torchvision import transforms, datasets

# 组合torchvision提供的各个transform
data_transform = transforms.Compose([
        transforms.RandomSizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
# 使用 ImageFolder 读取图片数据集
hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train',
                                           transform=data_transform)
# 用 DataLoader 封装
dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,
                                             batch_size=4, shuffle=True,
                                             num_workers=4)
```