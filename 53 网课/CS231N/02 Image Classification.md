
# 1. Image Classification 简介

- 计算机看到的图片是数字图像，即图像在计算机中的存储是数字化的，且存在 RGB 三个通道
- 这使得对图像的识别十分困难，这称之为 Semantic Gap : 我们赋予给图像的语义标签（如猫咪）和计算机实际看到的像素值之间有巨大的差距
- 对图像微小的改变可能使得整个像素网络发生变化（如猫的不同形态），此外形态、照明、变形、遮挡、背景混乱、类内差异都使得识别十分困难

# 2. Data-Driven Approach （数据驱动方法）

- 数据驱动方法可以概述为下述步骤：
    1. 收集图像和对应标签的数据集
    2. 使用机器学习算法训练一个分类器
    3. 使用分类器对新图片进行分类
- 对于数据驱动类的算法，一般我们会有如下两个 API 接口，一个是训练函数，接受图片和训练标签，然后输出模型，另一个是预测函数，接收一个模型，然后对图片分类
```py
def train(images, labels):
    # Machine learning
    return model

def predict(model, test_images):
    # Use model to predict labels
    return test_labels
```
- 本课程主要讨论神经网络、卷积神经网络和深度学习，它们的本质实际上也都是数据驱动类的算法，数据驱动类的算法势必深度学习更广义的一种概念

# 3. 临近分类器

## 3.1 Nearest Neighbor （最近邻分类器）

- 最近邻分类器算法：
    - train : 记录所有数据和标签
    - predict : 对于测试样本，计算其和训练集中最相近的图片，预测该图片的标签
-  CIFAR-10 是一个很常用的图像分类简单数据集，其包含 10 个类别，共包含 50000 个训练样本和 10000 个测试样本

**图像的比较方法**

- L1 距离，也叫曼哈顿距离，计算公式如下，其中 p 指每个位置的像素

$$d_1(I_1, I_2) = \sum_{p}|I_1^p-I_2^p|$$

- L2 距离，也叫欧氏距离，计算公式如下

$$d_1(I_1, I_2) = \sqrt{\sum_{p}(I_1^p-I_2^p)^2}$$

- 选择不同的距离，会在预测空间里，对底层的几何或者拓扑结构，做出不同假设，L1 像是一个正方形，而 L2 像是一个圆，其中 L1 会受你所确定的坐标系统影响而 L2 不会
- L1 存在坐标系依赖，若向量中的分量具有重要的意义，那么也许 L1 更合适，如果只是空间中的一个通用向量，不知道其中元素所代表的具体含义，那么 L2 更自然一些，但最好的方式就是都尝试一下（距离函数的选择也算是一个超参数）


**实现代码**



**相关问题**

> -  问：对于 N 个样本，最近邻算法的训练和预测的时间复杂度分别为多少？
> - 答：训练 O(1)，预测 O(N)
- 上述复杂度说明该算法很不好，我们想要分类器在执行预测时尽量快速，而训练过程缓慢一点是可以接受的
- 最近邻可能对一些异常点十分敏感使得部分小区域的分类是错误的，基于此原因，在最邻近的基础上进行改进，产生了 K-近邻算法，它不止寻找于最近的点，而是寻找最近的 K 个点，然后用着 K 个点进行投票，预测出结果
- 在使用临近算法时，总会使用一个较合适的 K 使得决策边界更加平滑

## 3.2 k-Nearest Neighbor, k-NN （k 近邻分类）

- 我们只要确定了距离度量的方式，我们就可以将 kNN 泛华到其他不同数据类型上而不仅仅是图片，例如对于文本数据，我们只要确定一个距离函数，能够计算两端文本之间的距离，那么我们就能对其使用 kNN 算法

**kNN 的问题**

- 在图像分类中几乎不使用
- 其测试时间过长，且像欧氏距离这种衡量标准用在比较图像上不合适，很难真正地衡量图像之间的距离
- 理论：若想要样本密集地分布在空间中，我们需要指数倍的训练数据，这样才具有足够密集地数据，但我们实际上不可能得到这么多的图片去密布（比如对于 $8 \times 8 \times 3$ 的图，密集指的是 $base^{192}$，比如 base 可以是 4）
- 根据上述理论，kNN 还存在**维度灾难**的问题：若要使用 kNN 达到一个较好的分类效果，需要有足够密集的数据分布在空间中，否则最近邻点的实际距离可能非常远（因为数据不够密集，我只能得到一个很远的点），此时得到的最近邻样本和待测样本的相似性其实并不高，而需要密集的数据样本空间，我们需要指数倍的数据量，这就造成了维度灾难

# 4. Hyperparameters （超参数）

- 超参数是我们提前为算法设定的一些值，它们是事先设置的，不是学习到的，比如前面 KNN 中，选择 k 的值和选择什么距离函数就是超参数
- 超参数的设置依赖于具体的问题，我们需要为数据尝试不同的超参数，并找出哪一个是最好的

**设置超参数**

- 将数据集分为训练集、验证集、测试集三组 (train, val, test)
- 在训练集上使用不同的超参数来训练不同的模型
- 然后在验证集上进行评估，选择出在验证集上表现最好的模型
- 然后把在验证集上表现最佳的分类器拿出来，在测试集上跑一跑，这才是你要写到论文中的数据（在没有见过的数据上表现如何）
- 必须分隔验证集和测试集，这点非常重要，做研究报告时，往往只在最后一刻才会接触到测试集，以确保没有造假，也没有给出偏差的数据
- 在选取出最好的超参数后，若时间来得及，可以使用最终确定的超参数，在训练集和验证集上进行重新训练，得到最终的模型

**交叉验证**

- 另一个设置超参数的策略是交叉验证，这在小数据集中更常用一些，在深度学习中不那么常用
- 保留出测试集，然后将剩余数据划分为 k 个 fold
- 对于一组超参数，轮流将这 k 个 fold 作为验证集，其他的 k-1 个作为 训练集，并计算平均值得到这组超参数的评估
- 在深度学习中，训练大型模型时，训练本身非常消耗计算能力，因此无法进行交叉验证


# 5. Linear Classification （线性分类）

- 线性分类器是神经网络的基础构建，一个神经网络是由多个线性分类器配合其他组件组合构成的
- 参数模型：以 CIFAR-10 为例，对于输入 $x$，参数矩阵 $W$，我们训练得到模型 $f(x, W)$ ，其计算并最终得到 10 个数字，它们分别表示属于这 10 个类别的相关分数，最终使用这些分数来确定该样本 $x$ 属于的类别
- 线性分类器是参数模型中最简单的例子，模型可以描述为 $f(x, W) = Wx$，即简单地对输入样本的各个分量进行线性组合，其中 x 是输入图像的大小， $(32, 32, 3)$ 展开为列向量 $(3072, 1)$，而参数矩阵 $W$ 规模为 $(10, 3072)$，经过线性组合，得到 10 个数字，分别表示该图片在 10 个分类上的得分
- 通常，我们还会添加一个偏置项，它是一个 10 元素的常数向量，它不和训练数据交互，因此最终的线性分类器模型描述为：$f(x, W) = Wx + b$
- 线性分类器存在一定的局限性，比如当前类别不是线性可分的时候，线性分类器可能不是工作的很好
- 如何训练 $W$ 将在下节课讨论


