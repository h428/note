
# 1. MySQL 架构与历史

- MySQL 的架构可以在多种不同场景中应用并发挥好的作用，但也会带来一些选择上的困难
- MySQL 不够完美，但足够灵活
- MySQL 最独特的地方是它的存储引擎架构，这种架构的设计将查询处理（Query Processing）以及其他系统任务（Server Task）和数据的存储/提取相分离
- 这种处理和存储分离的设计可以在使用时根据性能、特性，以及其他需求来选择数据存储的方式

## 1.1 MySQL 逻辑架构

- MySQL 架构大致可分为三层：客户端、核心服务层、存储引擎层
- 客户端 : 该层是最上层的服务，其 MySQL 所有独，大多数基于网络的客户端/服务器（CS 架构）的工具或服务都有类似架构（如 redis, mq 等），其一般包含连接处理、授权认证、安全等功能
- MySQL 服务器层 : 这是 MySQL 的第二层，也是核心服务层，大多数 MySQL 的核心服务功能都在这一层实现，包括查询解析、分析、优化、缓存以及所有的内置函数，所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等
- 存储引擎 : 负责 MySQL 中数据的存储和提取，每个存储引擎都有它的优势和劣势，服务器通过 API 与存储引擎进行通信，这些 API 评比了不同存储引擎之间的差异，使得这些差异对上层的查询过程透明
- 存储引擎 API 包含了十几个底层函数，用于执行诸如 “开始一个事务” 或者 “根据主键提取一条记录” 这样的操作，但存储引擎不会去解析 SQL（InnoDB 例外，InnoDB会解析外键定义，因为 MySQL 服务器本身没有实现该功能），不同的存储引擎之间也不会互相通信，只是简单地被上次服务器调用以响应上层服务器的请求

### 1.1.1 连接管理与安全性

- 每个客户端连接都会在服务器进程中拥有一个对应的线程，这个客户端连接的相关查询，服务器会使用这个对应的单独线程进行处理，显然该线程只能轮流在某个 CPU 核心或者 CPU 中运行
- 服务器会负责缓存线程（应该是维护了线程池），因此不需要为每一个新建的连接创建或者销毁线程（MySQL 5.5 或者更新的版本提供了一个 API，支持线程池（Thread-Pooling）插件，可以使用池中少量的线程来服务大量的连接）
- 当客户端连接到 MySQL 服务器时，服务器需要对其进行认证，认证基于用户名、原始主机信息和密码
- 如果使用了安全套接字（SSL）的方式连接，还可以使用 X.509 证书认证
- 一旦客户端连接成功，服务器会进一步查询该客户端的权限（例如是否对某表具有查询权限）

### 1.1.2 执行与优化

- MySQL 会解析查询，并创建内部数据结构（解析树），然后对其进行各种优化，包括重写查询、决定表的读取顺序、选择合适的索引等
- 可以通过特殊的关键字提示（hint）优化器，以影响其决策过程，例如 `SELECT /*! SQL_NO_CACHE */ columns FROM table;`
- 也可以请求优化器解释（explain）优化过程的各个因素，使用户知道对于某语句服务器是如何进行优化决策的，并提供一个参考基准，便于用户重构查询和 schema、修改相关配置，以使应用尽可能高效
- 优化器不关心表使用的是什么存储引擎，但存储引擎对于优化查询是有影响的（理解：SQL 的解析和使用什么存储引擎无关，但存储引擎的选择会影响 SQL 的效率）
- 优化器会请求存储引擎提供容量或者某个具体操作的开销信息，以及表数据额统计信息
- 比如，某些存储引擎的某种索引，可能对一些特定的查询有优化
- 关于索引与 schema 的优化将在 4, 5 章讨论，更多优化器细节将在第 6 章讨论
- 对于 select 语句，在解析查询之前，服务器会先检查查询缓存（Query Cache），如果缓存命中，服务器不必再执行查询解析、优化和执行的整个过程，直接返回缓存中的结果集即可，更多相关内容参考第 7 章

## 1.2 并发控制

- 当多个查询需要在同一时刻修改数据，都会产生并发控制的问题
- MySQL 的并发控制包括两个层面：服务器层与存储引擎层

### 1.2.1 读写锁

- 解决经典并发问题的方法就是并发控制，其通过实现一个由两种类型组合的锁系统来解决问题
- 这两种类型的锁通常称为共享锁（shared lock）和排它锁（exclusive lock），也叫作读锁（read lock）和写锁（write lock）
- 读锁是共享的，相互不阻塞，多个客户在同一时刻可以同时读取同一个资源，且互不干扰
- 写锁是排他的，也就是说一个写锁会阻塞其他的写锁和读锁，以确保在给定的时间里，只有一个用户能执行写入，并防止其他用户读取正在写入的同一资源
- 在实际的数据库系统中，每时每刻都在发生锁定，当每个用户在修改某一部分数据时，MySQL 会通过锁定防止其他用户读取同一数据
- 大多数时候，MySQL 锁的内部管理都是透明的

### 1.2.2 锁粒度

- 加锁也需要消耗资源，锁的各种操作，包括获得锁、检查锁是否已经解除、释放锁等都会增加系统的开销，如果系统花费大量的时间来管理锁而不是存取数据，那么系统的性能可能会因此受到影响，因此锁粒度的选取也很重要
- 所谓的所策略，就是在锁的开销和数据的安全性之间寻求平衡，这种平衡也会影响到性能
- 大多数商业数据库系统都是使用行级锁（row-lecel lock），并以各种复杂的方式来实现，以便在锁比较多的情况下尽可能地提供更好的性能
- MySQL 提供了多种选择，每种存储引擎都可以实现自己的锁策略和锁粒度，下面主要介绍最重要的两种

**表锁（table lock）**

- 表锁是 MySQL 中最基本的锁策略，并且是锁开销最小的策略，其锁定整张表
- 一个用户在对表进行写操作（插入、删除、更新等）前，需要先获得写锁，这会阻塞其他用户对该表的所有读操作，只有没有写锁时，其他读取的用户才能获得读锁，读锁之间不互相阻塞
- 在特定的场景中，表锁也可能有良好的性能，例如，READ LOCAL 表锁支持某些类型的并发写操作
- 写锁比读锁有更高的优先级，因此一个写锁请求可能会被插入到读锁队列的前面
- 尽管存储引擎可以管理自己的锁，但 MySQL 本身还是会使用各种有效的表锁来实现不同的目的，例如，服务器会为诸如 alter table 之类的语句使用表锁，而忽略存储引擎的锁机制

**行级锁（row lock）**

- 行级锁可以最大程度地支持并发处理（但同时也带来了最大的锁开销）
- 在 InnoDB 和 XtraDB，以及其他一些存储引擎中实现了行级锁
- 行级锁只在存储引擎层实现，而 MySQL 服务器层没有实现，服务器层完全不了解存储引擎中的锁实现
- 在本章的后续内容以及全书中，所有的存储引擎都以自己的方式展示了锁机制

## 1.3 事务

- 事务就是一组原子性的 SQL 查询，或者说一个独立的工作单元，事务内的语句，要么全部执行成功，要么全部执行失败
- 银行应用是解释事务必要性的一个经典例子，假设银行数据库有两张表：支票（checking）和储蓄（savings），用户 Jane 现要从支票账户转移 200 美元到她的储蓄扎昂胡，那么至少需要三个步骤：
    - 检查支票账户的余额高于 200 美元
    - 从支票账户余额中减去 200 美元
    - 在储蓄账户余额中增加 200 美元
- 上述三个步骤的操作必须打包在一个事务中，任何一个步骤失败，则必须回滚所有的步骤
- 可以使用 start transaction 语句开始一个事务，然后使用 commit 提交或者使用 rollback 回滚
```sql
start transaction;
select balance from checking where customer_id = 101;
update checking set balance = balance - 200.00 where customer_id = 101;
update savings  set balance = balance + 200.00 where customer_id = 101;
commit
```
- 事务具有 ACID 特性，即原子性（atomicity）、一致性（consistency）、隔离性（isolation）、持久性（durability）：
    - 原子性：一个事务必须看做完整的不可分割的最小工作单元，整个事务中的操作要么全部提交成功，要么全部失败回滚，不能只执行其中的一部分
    - 一致性：数据库总是从一个一致性的状态到另一个一致性状态的转换，在前面的例子中，一致性确保了，即使在第三、四条语句执行之间时系统崩溃，支票账户也不会损失 200 美元，因为事务最终没有提交，所以事务所做的修改不会保存到数据库中
    - 隔离性：**通常来说**，一个事务所做的修改在最终提交以前，对其他事务是不可见的（但和具体的隔离级别有关）
    - 持久性：一旦事务提交，则其所做的修改就会永久保存到数据库中，此时即使系统奔溃，修改的数据也不会丢失（实际上持久性也分很多级别，且不可能做到 100% 的持久性保证）
- 事务的 ACID 特性可以确保银行不弄丢你的钱，但在实际应用逻辑中，要做到这一点非常困难，甚至可以说是不可能完成的任务，一个兼容 ACID 的数据库系统，需要很多复杂但用户并没有察觉到的工作，才能确保 ACID 的实现
- 此外，事务处理过程的额外安全性，也会增加数据库系统的开销

### 1.3.1 隔离级别

- 隔离性其实比想象中要复杂，在 SQL 标准中定义了四种隔离级别，每一种级别都规定了一个事务中所做的修改（还没有提交），其他事务是否可见
- 较低的隔离级别通常可以执行更高的并发，系统的开销也更低
- 四种隔离级别：读未提交、读已提交、可重复读、可串行化

**读未提交（read uncommitted）**

- 在该隔离级别中，即使事务没有提交，当前事务所做的修改对其他事务也是可见的
- 其他事务可以读取未提交的数据，也称作脏读（Dirty Read）
- 这个级别会导致很多问题，从性能来说，不会比其他级别好太多，却缺乏其他级别的很多好处，因此实际中基本不使用

**读已提交（read committed）**

- 读已提交解决脏读问题
- 大多数数据库系统的默认隔离级别都是读已提交（但 MySQL 不是，MySQL 是可重复读）
- 读已提交满足前面隔离性的基本定义：一个事务开始时，只能看见已经提交的事务所做的修改
- 对于该级别，开启本事务后，执行查询，然后别的事务修改相关数据并提交成功后，在本事务再次做相同查询，发现可以读到别的事务已经提交的数据（读已提交），但同时也导致了在本事务中相同语句的多次查询得到不同的结果（不可重复读）

**可重复读（repeatable read）**

- 可重复读则在读已提交的基础上保证了在同一个事务中多次读取同样的记录结果是一样的
- 也就是说，在当前事务开启后，之后的所有记录读取都保持和开启时刻的数据状态一致，因此即使在当前事务的执行过程中有别的事务修改（注意是修改但不是新增）了数据，本事务也不会感应到
- 但可重复读仍然会产生幻读，例如在当前事务开启事务并全表查询后，别的事务新增了一条数据并成功提交后，由于可重复读，当前查询数据仍然会保持旧的，但在当前事务执行全表更新之类的操作后，再重新查询，却多出一条数据（假设原表只有两条数据，我原来查询只有两条，却全表更新了三条，莫名其妙多出来一条数据，好像产生了幻觉）
- 脏读、不可重复读都主要针对已经读取的单记录的不同步来说的，而幻读主要增对新增记录和全表读取（或者某个范围内）之类的不同步来说的
- 原句 : 所谓幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前事务再次读取该范围内的记录时，会产生幻行（Phantom Row）
- 可重复读是 MySQL 的默认隔离级别

**可串行化（serializable）**

- 可串行化是最高的隔离级别
- 其通过强制事务串行执行，避免了前面所说的幻读问题
- Serializable 会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题，因而实际中也基本不会采用该隔离级别

## 1.3.2 死锁

- 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象
- 当多个事务视图以不同的顺序锁定资源时，就可能产生死锁，例如以不同的顺序更新两行数据，则可能导致死锁
```sql
-- trans1
start transaction;
update admin set age = 21 where id = 1; -- 卡在这执行另一个事务
update admin set age = 22 where id = 2;
commit;

-- sql2
start transaction;
update admin set age = 22 where id = 2; -- 卡在这继续执行另一个事务
update admin set age = 21 where id = 1;
commit;
```

- 并发时，若凑巧两个事务都执行了第一条 update 更新并锁定该当数据，然后每个事务尝试去执行第二条 update 语句，发现已被锁定，然后两个事务都等待对方释放锁，同时又保持着对方所需的资源，从而陷入死循环
- 为了解决这种问题，数据库系统实现了各种死锁检测和死锁超时机制，例如对于前面的例子，两个事务都执行了第二条 update 后，MySQL 会检测到死锁并自动回滚其中后一个执行的事务（MySQL 5.7 测试结果，Deadlock found when trying to get lock; try restarting transaction）
- InnoDB 目前处理死锁的方法是，将持有最少行级排它锁的事务进行回滚（这是相对比较简单的死锁回滚算法）
- 锁的行为和顺序是和存储引擎相关的，以同样的顺序执行，有的存储引擎会产生死锁，有的则不会
- 死锁产生有双重原因：有些是因为真正的数据冲突，这种情况通常很难避免，有些则是由于存储引擎的实现方式导致的
- 死锁发生后，只有部分或者完全回滚其中一个事务，才能打破死锁
- 对于事务型的系统，这是无法避免的，因此应用程序在设计时必须考虑如何处理死锁，大多数情况下只需重新执行因死锁回滚的事务即可

### 1.3.3 事务日志

- 事务日志可以帮助提高事务的效率，使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把修改行为记录到硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘
- 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序 I/O，而不像随机 I/O 需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得很多
- 事务日志持久后，内存中被修改的数据可以在后台慢慢地刷会到磁盘中，目前大多数的存储引擎都是这样实现的，我们通常称作预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘
- 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写会硬盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据，具体的恢复方式视存储引擎而定

### 1.3.4 MySQL 中的事务

- MySQL 提供了两种事务型的存储引擎：InnoDB 和 NDB Cluster，另外也支持一些第三方存储引擎也支持事务，比较知名的包括 XtraDB 和 PBXT，后面将详细讨论他们各自的特点

**自动提交（autocommit）**

- MySQL 默认采用自动提交（autocommit）模式，即若不显式地开始一个事务，每个查询都被当作一个事务执行提交操作
- 在当前连接中，可以通过设置 autocommit 变量来启用或者禁用自动提交模式：
```sql
show variables like 'autocommit';
set autocommit = 1; -- 1 启用，0 关闭
```
- 当 `autocommit = 0` 时，所有查询都是在一个事务中，直到显式地执行 commit 提交或者 rollback 回滚，且该事务结束的同时又开始了另一个新事物
- 修改 autocommit 对非实物型的表，例如 MyISAM 或者内存表，不会有任何影响
- 对这类表来说，没有 commit 或者 rollback 概念，也可以说是一直处于 autocommit 启用的模式
- 另外还有一些命令，在执行之前会强制的执行 commit 提交当前的活动事务，典型的例子就是在数据定义语言 DDL 中，如果是会导致大量数据改变的操作，比如 alter table 就会如此
- 另外还有 lock tables 等其他语句也会导致同样的结果，有需要，请检查对应版本的官方文档来确认所有可能导致自动提交的语句列表
- MySQL 可以通过 set transaction isolation level 命令来设置隔离级别，新的隔离级别会在下一个事务开始时生效
- 可以在配置文件中设置整个数据库的隔离级别，也可以只改变当前会话的隔离级别 `set session transaction isolation level read committed`

**在事务中混合使用存储引擎**

- MySQL 服务器层不管理事务，事务是由下层的存储引擎实现的，所以在同一事务中，使用多种存储引擎是不可靠的
- 在事务中混合使用了事务型和非事务型的表（例如 InnoDB 和 MyISAM 表），在正常提交的时候没什么问题，但如果该事物需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库除以不一致状态，事务的最终结果无法确定，因此要为每张表选择合适的存储引擎
- 在非事务型的表上执行事务相关操作时，MySQL 通常不会发出提醒也不会报错，有时只在回滚的时候发出一个景观：“某些非事务型的表上的变更不可能被回滚”

**隐式和显式锁定**

- InnoDB 采用的是两阶段锁定协议，在事务执行过程中，随时都可以执行锁定，锁只有在执行 commit 或者 rollback 时才能释放，并且所有的锁是在同一时刻被释放
- 前面描述的锁定都是隐式锁定，InnoDB 会根据隔离级别在需要的时候自动加锁
- 另外，InnoDB 也支持通过特定的语句进行显示锁定，这些语句不属于 SQL 规范（这些锁经常被滥用，实际上应当尽量避免使用，详细参第 6 章）
```sql
select ... lock in share mode
select ... for update
```
- MySQL 也支持 lock tables 和 unlock tables 语句，这是在服务器层实现的，和存储引擎无关
- 它们有自己的用途，但并不能代替事务处理，如果应用需要用到事务，还是应该选择事务型存储引擎
- 经常可以发现，应用已经将表从 MyISAM 转换到 InnoDB，但还是显式的使用 lock tables 语句，这不但没有必要还会严重影响性能，实际上 InnoDB 的行级锁工作得更好
- lock tables 和事务之间相互影响会使得情况变得非常复杂，在某些 MySQL 版本中甚至会产生无法预料的后果，因此，除了事务中显式禁用了 autocommit 和没有开启事务时可以使用 lock tables 外，其他任何时候都不要显式地执行 lock tables，不管使用的是什么存储引擎

## 1.4 多版本并发控制（MVCC）

- MySQL 的大多数事务型存储引擎实现的都不是简单的行级锁（包括读锁和写锁），基于提升并发性能的考虑，他们一般都实现了多版本并发控制（MVCC）
- 不仅是 MySQL，包括 Oracle、PostgreSQL 等其他数据库也都实现了 MVCC，但各自的实现机制不尽相同，因为 MVCC 没有一个统一的实现标准
- 可以认为 MVCC 是行级锁的一个变种，其在很多情况下避免了加锁的操作，因此开销更低，虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行
- 如果只是读写锁而没有 MVCC，理论上在一个事务对某行执行 update 时，由于写锁的排他性，其他事务是无法读取该记录的（会阻塞），但实际上 InnoDB 是可以在不阻塞的情况下做到这一点的（但同时 update 还是会阻塞的），这说明 InnoDB 并不是简单的读写锁，而是利用 MVCC 思想进行并发控制
- MVCC 是通过保存在某个时间点的快照来实现的，也就是说，不管需要执行多长时间，每个事务看到的数据都是一致的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的
- 不同存储引擎的 MVCC 实现是不同的，典型的有乐观并发控制和悲观并发控制（乐观悲观只是一种思想，可以有不同的实现）
- InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现的，这两列分别是创建时间和过期时间，但保存的不是时间而是系统版本号，为了方便描述，将其称作**创建版本**和**删除版本**
- 每个事务都有自己系统版本号，每开启一个新的事物，系统版本号自动递增，事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的创建版本和删除版本进行比较，以确定该时刻的对应记录，为了方便，将事务对应的版本号称作事务版本号
- 下面看一下可重复读隔离级别下，MVCC 具体是如何操作的：
    - select :
        - InnoDB 只查找创建版本早于当前事务版本号的行（行的创建版本号小于等于当前事务的系统版本号），以确保该事务读取的记录是在事务开始之前已存在，或者是本事务插入的
        - 此外，还要求行的删除版本要么未定义，要么大于当前事务版本号，以确定该记录在该事务之前没有被删除
    - insert : InnoDB 为新插入的每一行记录保存当前事务版本号到创建版本
    - delete : InnoDB 为删除的每一行记录保存当前事务版本号到删除版本
    - update : InnoDB 插入一条新数据并保存当前事务版本号到创建版本，同时将当前事务版本保存到原记录的删除版本，以表示在该事务之后，原记录全都被删除
- 保存这两个额外系统版本号，使大多数读操作都可以不必加锁，这样设计使得读操作很简单，性能很好，并且也能保证只会读取到符合标准的行，不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作
- MVCC 只在 repeatable read 和 read committed 两个隔离级别下工作，因为 read uncommitted 总是读取最新的数据行，而不是符合当前事务版本的数据行，而 serializable 会对所有读取的行都加锁

## 1.5 MySQL 的存储引擎

- MySQL 将每个数据库（也称之为 schema）保存为数据目录下的一个子目录
- 创建表时，会在对应的数据库子目录下创建一个和表同名的 .frm 文件以保存表的定义，例如创建 admin 表则会在 admin.frm 文件中保存该表的定义
- 由于 mysql 使用文件系统的目录和文件来保存数据库和表的定义，大小写敏感性和具体平台相关，在 win 中，大小写是不敏感的；而在类 Unix 中则是敏感的
- 不同的存储引擎保存数据和索引的方式是不同的，但表的定义则是在 MySQL 服务层统一处理的
- 可以使用 `show table status like 表名` 查询表的相关信息，相关列表示的含义如下：
    - Name : 表名
    - Engine : 存储引擎类型
    - Row_format : 行的格式，可选的值为 Dynamic、Fixed、Compressed
    - Rows : 表中的行数，对于 MyISAM 和其他存储引擎，该值是精确的，对于 InnoDB 该值是估计值
    - Avg_row_length : 平均每行包含的字节数
    - Data_length : 表数据的大小（以字节为单位）
    - Max_data_length : 表数据的最大容量，该值和存储引擎有关
    - Index_length : 索引的大小（以字节为单位）
    - Data_free : 对于 MyISAM 表，表示已分配但目前没有使用的空间，这部分空间包括之前删除的行，以及后续可以被 INSERT 利用到的空间
    - Auto_increment : 下一个 auto_increment 值
    - Create_time : 表的创建时间
    - update_time : 表数据的最后修改时间
    - Check_time : 使用 check table 命令或者 myisamhk 工具最后一次检查表的时间
    - Collation : 表的默认字符集和字符列排序规则
    - Checksum : 如果启用，保存的是整个表的实时校验和
    - Create_options : 如果启用，保存的是整个表的实时校验和
    - Comment : 其他一些额外信息

### 1.5.1 InnoDB 存储引擎

- 选择 InnoDB 就完事
- 暂时看不太懂，后期再看